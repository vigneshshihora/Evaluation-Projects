{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39629dd",
   "metadata": {},
   "source": [
    "# HR Analytics Project- Understanding the Attrition in HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff244eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "535f3d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
      "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
      "1   49        No  Travel_Frequently        279  Research & Development   \n",
      "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
      "3   33        No  Travel_Frequently       1392  Research & Development   \n",
      "4   27        No      Travel_Rarely        591  Research & Development   \n",
      "\n",
      "   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n",
      "0                 1          2  Life Sciences              1               1   \n",
      "1                 8          1  Life Sciences              1               2   \n",
      "2                 2          2          Other              1               4   \n",
      "3                 3          4  Life Sciences              1               5   \n",
      "4                 2          1        Medical              1               7   \n",
      "\n",
      "   ...  RelationshipSatisfaction StandardHours  StockOptionLevel  \\\n",
      "0  ...                         1            80                 0   \n",
      "1  ...                         4            80                 1   \n",
      "2  ...                         2            80                 0   \n",
      "3  ...                         3            80                 0   \n",
      "4  ...                         4            80                 1   \n",
      "\n",
      "   TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
      "0                  8                      0               1               6   \n",
      "1                 10                      3               3              10   \n",
      "2                  7                      3               3               0   \n",
      "3                  8                      3               3               8   \n",
      "4                  6                      3               3               2   \n",
      "\n",
      "  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
      "0                  4                        0                     5  \n",
      "1                  7                        1                     7  \n",
      "2                  0                        0                     0  \n",
      "3                  7                        3                     0  \n",
      "4                  2                        2                     2  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "(1470, 35)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Age                       1470 non-null   int64 \n",
      " 1   Attrition                 1470 non-null   object\n",
      " 2   BusinessTravel            1470 non-null   object\n",
      " 3   DailyRate                 1470 non-null   int64 \n",
      " 4   Department                1470 non-null   object\n",
      " 5   DistanceFromHome          1470 non-null   int64 \n",
      " 6   Education                 1470 non-null   int64 \n",
      " 7   EducationField            1470 non-null   object\n",
      " 8   EmployeeCount             1470 non-null   int64 \n",
      " 9   EmployeeNumber            1470 non-null   int64 \n",
      " 10  EnvironmentSatisfaction   1470 non-null   int64 \n",
      " 11  Gender                    1470 non-null   object\n",
      " 12  HourlyRate                1470 non-null   int64 \n",
      " 13  JobInvolvement            1470 non-null   int64 \n",
      " 14  JobLevel                  1470 non-null   int64 \n",
      " 15  JobRole                   1470 non-null   object\n",
      " 16  JobSatisfaction           1470 non-null   int64 \n",
      " 17  MaritalStatus             1470 non-null   object\n",
      " 18  MonthlyIncome             1470 non-null   int64 \n",
      " 19  MonthlyRate               1470 non-null   int64 \n",
      " 20  NumCompaniesWorked        1470 non-null   int64 \n",
      " 21  Over18                    1470 non-null   object\n",
      " 22  OverTime                  1470 non-null   object\n",
      " 23  PercentSalaryHike         1470 non-null   int64 \n",
      " 24  PerformanceRating         1470 non-null   int64 \n",
      " 25  RelationshipSatisfaction  1470 non-null   int64 \n",
      " 26  StandardHours             1470 non-null   int64 \n",
      " 27  StockOptionLevel          1470 non-null   int64 \n",
      " 28  TotalWorkingYears         1470 non-null   int64 \n",
      " 29  TrainingTimesLastYear     1470 non-null   int64 \n",
      " 30  WorkLifeBalance           1470 non-null   int64 \n",
      " 31  YearsAtCompany            1470 non-null   int64 \n",
      " 32  YearsInCurrentRole        1470 non-null   int64 \n",
      " 33  YearsSinceLastPromotion   1470 non-null   int64 \n",
      " 34  YearsWithCurrManager      1470 non-null   int64 \n",
      "dtypes: int64(26), object(9)\n",
      "memory usage: 402.1+ KB\n",
      "None\n",
      "               Age    DailyRate  DistanceFromHome    Education  EmployeeCount  \\\n",
      "count  1470.000000  1470.000000       1470.000000  1470.000000         1470.0   \n",
      "mean     36.923810   802.485714          9.192517     2.912925            1.0   \n",
      "std       9.135373   403.509100          8.106864     1.024165            0.0   \n",
      "min      18.000000   102.000000          1.000000     1.000000            1.0   \n",
      "25%      30.000000   465.000000          2.000000     2.000000            1.0   \n",
      "50%      36.000000   802.000000          7.000000     3.000000            1.0   \n",
      "75%      43.000000  1157.000000         14.000000     4.000000            1.0   \n",
      "max      60.000000  1499.000000         29.000000     5.000000            1.0   \n",
      "\n",
      "       EmployeeNumber  EnvironmentSatisfaction   HourlyRate  JobInvolvement  \\\n",
      "count     1470.000000              1470.000000  1470.000000     1470.000000   \n",
      "mean      1024.865306                 2.721769    65.891156        2.729932   \n",
      "std        602.024335                 1.093082    20.329428        0.711561   \n",
      "min          1.000000                 1.000000    30.000000        1.000000   \n",
      "25%        491.250000                 2.000000    48.000000        2.000000   \n",
      "50%       1020.500000                 3.000000    66.000000        3.000000   \n",
      "75%       1555.750000                 4.000000    83.750000        3.000000   \n",
      "max       2068.000000                 4.000000   100.000000        4.000000   \n",
      "\n",
      "          JobLevel  ...  RelationshipSatisfaction  StandardHours  \\\n",
      "count  1470.000000  ...               1470.000000         1470.0   \n",
      "mean      2.063946  ...                  2.712245           80.0   \n",
      "std       1.106940  ...                  1.081209            0.0   \n",
      "min       1.000000  ...                  1.000000           80.0   \n",
      "25%       1.000000  ...                  2.000000           80.0   \n",
      "50%       2.000000  ...                  3.000000           80.0   \n",
      "75%       3.000000  ...                  4.000000           80.0   \n",
      "max       5.000000  ...                  4.000000           80.0   \n",
      "\n",
      "       StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  \\\n",
      "count       1470.000000        1470.000000            1470.000000   \n",
      "mean           0.793878          11.279592               2.799320   \n",
      "std            0.852077           7.780782               1.289271   \n",
      "min            0.000000           0.000000               0.000000   \n",
      "25%            0.000000           6.000000               2.000000   \n",
      "50%            1.000000          10.000000               3.000000   \n",
      "75%            1.000000          15.000000               3.000000   \n",
      "max            3.000000          40.000000               6.000000   \n",
      "\n",
      "       WorkLifeBalance  YearsAtCompany  YearsInCurrentRole  \\\n",
      "count      1470.000000     1470.000000         1470.000000   \n",
      "mean          2.761224        7.008163            4.229252   \n",
      "std           0.706476        6.126525            3.623137   \n",
      "min           1.000000        0.000000            0.000000   \n",
      "25%           2.000000        3.000000            2.000000   \n",
      "50%           3.000000        5.000000            3.000000   \n",
      "75%           3.000000        9.000000            7.000000   \n",
      "max           4.000000       40.000000           18.000000   \n",
      "\n",
      "       YearsSinceLastPromotion  YearsWithCurrManager  \n",
      "count              1470.000000           1470.000000  \n",
      "mean                  2.187755              4.123129  \n",
      "std                   3.222430              3.568136  \n",
      "min                   0.000000              0.000000  \n",
      "25%                   0.000000              2.000000  \n",
      "50%                   1.000000              3.000000  \n",
      "75%                   3.000000              7.000000  \n",
      "max                  15.000000             17.000000  \n",
      "\n",
      "[8 rows x 26 columns]\n",
      "Age                         0\n",
      "Attrition                   0\n",
      "BusinessTravel              0\n",
      "DailyRate                   0\n",
      "Department                  0\n",
      "DistanceFromHome            0\n",
      "Education                   0\n",
      "EducationField              0\n",
      "EmployeeCount               0\n",
      "EmployeeNumber              0\n",
      "EnvironmentSatisfaction     0\n",
      "Gender                      0\n",
      "HourlyRate                  0\n",
      "JobInvolvement              0\n",
      "JobLevel                    0\n",
      "JobRole                     0\n",
      "JobSatisfaction             0\n",
      "MaritalStatus               0\n",
      "MonthlyIncome               0\n",
      "MonthlyRate                 0\n",
      "NumCompaniesWorked          0\n",
      "Over18                      0\n",
      "OverTime                    0\n",
      "PercentSalaryHike           0\n",
      "PerformanceRating           0\n",
      "RelationshipSatisfaction    0\n",
      "StandardHours               0\n",
      "StockOptionLevel            0\n",
      "TotalWorkingYears           0\n",
      "TrainingTimesLastYear       0\n",
      "WorkLifeBalance             0\n",
      "YearsAtCompany              0\n",
      "YearsInCurrentRole          0\n",
      "YearsSinceLastPromotion     0\n",
      "YearsWithCurrManager        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "url = \"https://github.com/FlipRoboTechnologies/ML_-Datasets/raw/main/HR%20Analytics/ibm-hr-analytics-employee-attrition-performance.zip\"\n",
    "df = pd.read_csv(url, compression='zip')\n",
    "\n",
    "# Explore the data\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Data preprocessing\n",
    "df.drop('EmployeeNumber', axis=1, inplace=True)\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Feature engineering (if necessary)\n",
    "# e.g., scaling, encoding, etc.\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X = df.drop('Attrition_Yes', axis=1)\n",
    "y = df['Attrition_Yes']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b0812c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8673469387755102\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       255\n",
      "           1       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.87       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.75      0.87      0.81       294\n",
      "\n",
      "--------------------------------------------------\n",
      "Training Decision Tree\n",
      "Accuracy: 0.7619047619047619\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86       255\n",
      "           1       0.17      0.21      0.19        39\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.52      0.53      0.52       294\n",
      "weighted avg       0.78      0.76      0.77       294\n",
      "\n",
      "--------------------------------------------------\n",
      "Training Random Forest\n",
      "Accuracy: 0.8775510204081632\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       255\n",
      "           1       0.80      0.10      0.18        39\n",
      "\n",
      "    accuracy                           0.88       294\n",
      "   macro avg       0.84      0.55      0.56       294\n",
      "weighted avg       0.87      0.88      0.83       294\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(\"Training\", name)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b41c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.8401360544217689\n",
      "Standard Deviation of Accuracy: 0.0037260037925521544\n",
      "Cross-validation Scores: [0.83673469 0.83673469 0.84693878 0.84013605 0.84013605]\n",
      "--------------------------------------------------\n",
      "Evaluating Decision Tree\n",
      "Mean Accuracy: 0.7850340136054422\n",
      "Standard Deviation of Accuracy: 0.022293836201597222\n",
      "Cross-validation Scores: [0.78231293 0.76870748 0.82312925 0.7585034  0.79251701]\n",
      "--------------------------------------------------\n",
      "Evaluating Random Forest\n",
      "Mean Accuracy: 0.8591836734693876\n",
      "Standard Deviation of Accuracy: 0.007003830027882321\n",
      "Cross-validation Scores: [0.8537415  0.86054422 0.8707483  0.85034014 0.86054422]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Function to perform cross-validation and evaluate performance metrics\n",
    "def evaluate_model(model, X, y):\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Compute additional performance metrics\n",
    "    mean_accuracy = cv_scores.mean()\n",
    "    std_accuracy = cv_scores.std()\n",
    "    \n",
    "    return mean_accuracy, std_accuracy, cv_scores\n",
    "\n",
    "# Evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(\"Evaluating\", name)\n",
    "    mean_accuracy, std_accuracy, cv_scores = evaluate_model(model, X, y)\n",
    "    print(\"Mean Accuracy:\", mean_accuracy)\n",
    "    print(\"Standard Deviation of Accuracy:\", std_accuracy)\n",
    "    print(\"Cross-validation Scores:\", cv_scores)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1778896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best Score: 0.853746844572665\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "becd4e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a08e3e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Train the Random Forest model with the best parameters\n",
    "best_rf_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(best_rf_model, 'best_random_forest_model.pkl')\n",
    "\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd3766",
   "metadata": {},
   "source": [
    "the Random Forest model was chosen as the final model based on several factors:\n",
    "\n",
    "Performance Metrics: The Random Forest model exhibited the highest accuracy and better precision, recall, and F1-score for predicting employees who left the company (class 1) compared to Logistic Regression and Decision Tree models. This indicates that the Random Forest model performs better in identifying employees at risk of attrition.\n",
    "\n",
    "Cross-Validation Mean Accuracy: The Random Forest model demonstrated a higher cross-validation mean accuracy (0.859) compared to Logistic Regression (0.840) and Decision Tree (0.785). This indicates that the Random Forest model generalizes well to unseen data and is less likely to overfit.\n",
    "\n",
    "Robustness: Random Forest models are known for their robustness to overfitting, noise, and outliers in the data. By aggregating predictions from multiple decision trees, Random Forest models reduce variance and improve predictive performance.\n",
    "\n",
    "Hyperparameter Tuning: The Random Forest model underwent hyperparameter tuning using GridSearchCV to search for the best combination of hyperparameters, further optimizing its performance.\n",
    "\n",
    "Overall Performance: Considering both training and cross-validation results, the Random Forest model consistently outperformed the other models across multiple performance metrics, making it the preferred choice for predicting employee attrition in this project.\n",
    "\n",
    "These factors collectively influenced the decision to select the Random Forest model as the final model for predicting employee attrition in HR analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c8bfe2",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "\n",
    "In this HR Analytics project, we aimed to understand and analyze employee attrition within companies using machine learning techniques. Here are the key conclusions drawn from our analysis:\n",
    "\n",
    "Impact of Attrition on Companies:\n",
    "\n",
    "High employee attrition poses significant challenges for organizations, including increased costs associated with hiring, training, and loss of collective knowledge and experience.\n",
    "Attrition affects various aspects of business operations, including customer satisfaction and overall productivity.\n",
    "Role of HR Analytics:\n",
    "\n",
    "HR Analytics plays a crucial role in addressing attrition issues by providing insights into employee behavior, identifying factors contributing to attrition, and informing strategic decisions to retain top talent.\n",
    "It goes beyond simply gathering data on employee efficiency and aims to optimize HR processes to improve employee performance and organizational effectiveness.\n",
    "Model Evaluation:\n",
    "\n",
    "We built and evaluated multiple machine learning models, including Logistic Regression, Decision Tree, and Random Forest, to predict employee attrition.\n",
    "Among these models, the Random Forest model emerged as the best performing one, demonstrating higher accuracy and better precision, recall, and F1-score for predicting employees who left the company.\n",
    "Hyperparameter Tuning:\n",
    "\n",
    "We performed hyperparameter tuning for the Random Forest model using GridSearchCV to optimize its performance further.\n",
    "The tuned Random Forest model achieved improved accuracy and generalization ability, making it suitable for deployment in real-world scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec96d790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
